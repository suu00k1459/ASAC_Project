{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71252519-4876-442f-a260-05d509854068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from mlxtend) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from mlxtend) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from mlxtend) (3.8.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.1-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.4 MB 825.8 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.3/1.4 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.7/1.4 MB 4.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.4 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.4 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.4 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90fd2c68-b485-438f-ad06-18aa1facd275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas-profiling\n",
      "  Downloading pandas_profiling-3.2.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting joblib~=1.1.0 (from pandas-profiling)\n",
      "  Downloading joblib-1.1.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas-profiling) (1.11.4)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas-profiling) (2.1.4)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas-profiling) (3.8.0)\n",
      "Requirement already satisfied: pydantic>=1.8.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas-profiling) (1.10.12)\n",
      "Requirement already satisfied: PyYAML>=5.0.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas-profiling) (6.0.1)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas-profiling) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.1.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas-profiling) (2.1.3)\n",
      "Collecting visions==0.7.4 (from visions[type_image_path]==0.7.4->pandas-profiling)\n",
      "  Downloading visions-0.7.4-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas-profiling) (1.26.4)\n",
      "Collecting htmlmin>=0.1.12 (from pandas-profiling)\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting missingno>=0.4.2 (from pandas-profiling)\n",
      "  Downloading missingno-0.5.2-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting phik>=0.11.1 (from pandas-profiling)\n",
      "  Downloading phik-0.12.4-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting tangled-up-in-unicode==0.2.0 (from pandas-profiling)\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: requests>=2.24.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas-profiling) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas-profiling) (4.65.0)\n",
      "Requirement already satisfied: seaborn>=0.10.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas-profiling) (0.12.2)\n",
      "Collecting multimethod>=1.4 (from pandas-profiling)\n",
      "  Downloading multimethod-1.11.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from visions==0.7.4->visions[type_image_path]==0.7.4->pandas-profiling) (23.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from visions==0.7.4->visions[type_image_path]==0.7.4->pandas-profiling) (3.1)\n",
      "Collecting imagehash (from visions[type_image_path]==0.7.4->pandas-profiling)\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (10.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from pydantic>=1.8.1->pandas-profiling) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from tqdm>=4.48.2->pandas-profiling) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.2.0->pandas-profiling) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\nt551xcj\\anaconda3\\lib\\site-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling) (1.5.0)\n",
      "Downloading pandas_profiling-3.2.0-py2.py3-none-any.whl (262 kB)\n",
      "   ---------------------------------------- 0.0/262.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 262.6/262.6 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.7 MB 9.6 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.6/4.7 MB 6.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.9/4.7 MB 6.2 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.0/4.7 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.6/4.7 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.0/4.7 MB 7.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.4/4.7 MB 7.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.6/4.7 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.0/4.7 MB 7.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.3/4.7 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.7/4.7 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.6/4.7 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.7/4.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 7.2 MB/s eta 0:00:00\n",
      "Downloading visions-0.7.4-py3-none-any.whl (102 kB)\n",
      "   ---------------------------------------- 0.0/102.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 102.4/102.4 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
      "   ---------------------------------------- 0.0/309.8 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 225.3/309.8 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  307.2/309.8 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 309.8/309.8 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading missingno-0.5.2-py3-none-any.whl (8.7 kB)\n",
      "Downloading multimethod-1.11.2-py3-none-any.whl (10 kB)\n",
      "Downloading phik-0.12.4-cp311-cp311-win_amd64.whl (667 kB)\n",
      "   ---------------------------------------- 0.0/667.1 kB ? eta -:--:--\n",
      "   ------------- ------------------------- 235.5/667.1 kB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  665.6/667.1 kB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 667.1/667.1 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "   ---------------------------------------- 0.0/296.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 296.5/296.5 kB 9.2 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: htmlmin\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27091 sha256=4905b28e4d0e727c86ced22eb0b1cde796387db2202b0c4c409503b2861284c4\n",
      "  Stored in directory: c:\\users\\nt551xcj\\appdata\\local\\pip\\cache\\wheels\\8d\\55\\1a\\19cd535375ed1ede0c996405ebffe34b196d78e2d9545723a2\n",
      "Successfully built htmlmin\n",
      "Installing collected packages: htmlmin, tangled-up-in-unicode, multimethod, joblib, imagehash, visions, phik, missingno, pandas-profiling\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.2.0\n",
      "    Uninstalling joblib-1.2.0:\n",
      "      Successfully uninstalled joblib-1.2.0\n",
      "Successfully installed htmlmin-0.1.12 imagehash-4.3.1 joblib-1.1.1 missingno-0.5.2 multimethod-1.11.2 pandas-profiling-3.2.0 phik-0.12.4 tangled-up-in-unicode-0.2.0 visions-0.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6b3491-3e5c-403d-adda-a2f5efac509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef69455d-d355-4965-aafc-79650882f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링을 위한 웹드라이버\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as ec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30cbb17a-9d78-4460-b30e-72adeaa3ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39fec2c-b05d-4a2b-8d8b-ce41dcf3995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 페이지 수 확인하기\n",
    "def make_info(brand_num, driver):\n",
    "    \n",
    "    url =f'https://www.albamon.com/alba-talk/review/{brand_num}?pageIndex=1&recommendCode=ALL'\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    tot_review = soup.find(\"div\",{\"class\":\"Typography_typography__53V55 Typography_typography--B2__60_O6 Typography_typography--regular__qCojp review-detail__total\"}).text\n",
    "    tot_num = int(re.findall(r\"\\d+\",tot_review)[0])\n",
    "    \n",
    "    reviewPerPage = len(soup.find_all(\"div\", {\"class\":\"ReviewAccordionList_review-accordion-list__JSPom\"}))\n",
    "    \n",
    "    pages = math.ceil(tot_num/reviewPerPage)\n",
    "\n",
    "    return brand_num, pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d7a4ed3-345a-4d18-8764-2e7144483a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메인!! 데이터 크롤링 부분\n",
    "\n",
    "def make_DF(brand_num, first_pages, last_pages ,driver):\n",
    "    data=[]\n",
    "\n",
    "\n",
    "    # 끌어 올 페이지 지정 :\n",
    "    for page in range(first_pages,last_pages):\n",
    "        url =f'https://www.albamon.com/alba-talk/review/{brand_num}?pageIndex={page}&recommendCode=ALL'\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        temp = soup.find_all(\"div\", {\"class\":\"ReviewAccordionList_review-accordion-list__JSPom\"})\n",
    "        reviewPerPage = len(soup.find_all(\"div\", {\"class\":\"ReviewAccordionList_review-accordion-list__JSPom\"}))\n",
    "        \n",
    "      \n",
    "        # 리뷰 하나 클릭하고 데이터 긁어온 후 다시 페이지 로딩\n",
    "        for review_num in range(reviewPerPage):\n",
    "            if str(temp[review_num].find(\"i\")).split('\"')[3] ==\"Icon_icon__BlZpj icon-system_arrowDown\":\n",
    "                apple_btn_path = f'//*[@id=\"item_{review_num}summary\"]/div/div/div[2]/div[2]/i'\n",
    "                driver.find_element(By.XPATH, apple_btn_path).click()\n",
    "            \n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            \n",
    "            rv_Contents = soup.find_all(\"div\", {\"class\":\"ReviewAccordionList_review-accordion-list__JSPom\"})[review_num]\n",
    "            \n",
    "\n",
    "            # 데이터 시작\n",
    "            \n",
    "            idx = str(page)+\"_\"+str(review_num)           #페이지_리뷰순서 : 1페이지당 20개씩 있음!\n",
    "            recom = rv_Contents.find_all(\"span\")[0].text  #추천분류\n",
    "                                                    \n",
    "            workDate=rv_Contents.find(\"div\",{\"class\":\"Typography_typography__53V55 Typography_typography--B2__60_O6 Typography_typography--regular__qCojp ReviewTitleList_work-date__3KpKH\"}).text.split(\"~\")\n",
    "            work_StrDate = re.findall('[\\d+]',workDate[0]) #알바 시작일\n",
    "            work_EndDate = re.findall('[\\d+]',workDate[1]) #알바 종료일 (작성 당시 재직중일 수 있음)\n",
    "\n",
    "            if len(work_StrDate)==5: #1~9월 -> 01~-09 형태로 맞춰줌\n",
    "                work_StrDate.insert(4,'0')\n",
    "            if len(work_EndDate)==5:\n",
    "                work_EndDate.insert(4,'0')\n",
    "\n",
    "            work_StrDate =''.join(work_StrDate)\n",
    "            work_EndDate =''.join(work_EndDate)\n",
    "\n",
    "            \n",
    "            if rv_Contents.find_all(\"span\")[2].text ==\"재직중\": #재직여부 : 재직중=1, 퇴사=0\n",
    "                workOn = 1\n",
    "            else :\n",
    "                workOn = 0\n",
    "        \n",
    "    \n",
    "            tot_review = rv_Contents.find_all(\"div\",{\"class\":\"ReviewTitleList_accordion-chip__Hem28\"})[0]\n",
    "            plus_cnt = int(tot_review.find_all(\"span\")[0].text.split()[1])  #긍정리뷰 수\n",
    "            minus_cnt = int(tot_review.find_all(\"span\")[2].text.split()[1]) #부정리뷰 수\n",
    "\n",
    "            \n",
    "            Question=[]\n",
    "            Answer =[]\n",
    "            \n",
    "            k = len(rv_Contents.find_all(\"div\",{\"class\":\"ReviewDetailQna_review-detail-qna__Sh4TS\"})) #리뷰마다 질문이 달라서 인덱스로 부르려고 길이 확인\n",
    "            \n",
    "            for i in range(k):\n",
    "                if k==0:\n",
    "                    pass\n",
    "                else :\n",
    "                    QnA = rv_Contents.find_all(\"div\",{\"class\":\"ReviewDetailQna_review-detail-qna__Sh4TS\"})[i].find_all(\"div\")\n",
    "                    Q = QnA[0].text\n",
    "                    A= [QnA[2].find_all(\"span\", {\"class\":\"Chip_content__J_ZRW chip-content\"})[i].text for i in range(len(QnA[2].find_all(\"span\", {\"class\":\"Chip_content__J_ZRW chip-content\"})))]\n",
    "                    Question.append(Q)\n",
    "                    Answer.append(A)\n",
    "            # print(Answer)\n",
    "\n",
    "            if len(Answer)==0:\n",
    "                pass\n",
    "            else:\n",
    "                data.append([idx, recom,work_StrDate,work_EndDate,workOn,plus_cnt,minus_cnt,Answer[0],Answer[1],Answer[2],Answer[-2],Answer[-1]])\n",
    "            \n",
    "\n",
    "    return data ,Question\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5bbda6f-763b-4e55-814e-c83724de4d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페이지가 너무 많으면 끊기기 때문에 2번에 나눠서 불러옴 (시작, 끝 페이지 지정해줌)\n",
    "\n",
    "def make_brand(brand):\n",
    "    path = r\"C:\\Users\\NT551XCJ\\Desktop\\chromedriver-win64\\chromedriver.exe\"\n",
    "    s=Service(path)\n",
    "    driver = webdriver.Chrome(service =s)\n",
    "    \n",
    "    brand_num, pages = make_info(brand, driver)\n",
    "    \n",
    "    data_lst1, Question = make_DF(brand_num, 1, math.floor(pages/2)+1 ,driver)\n",
    "    data_lst2, Question2= make_DF(brand_num, math.floor(pages/2)+1, pages+1, driver)\n",
    "    \n",
    "    data_lst = data_lst1 + data_lst2\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(data_lst,\n",
    "                    columns=[\"idx\", \"recom\", \"work_StrDate\", \"work_EndDate\", \"workOn\", \"plus_cnt\", \"minus_cnt\", Question[0], Question[1],Question[2],Question[-2],Question[-1]])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c38837-dd6c-4d03-b810-2a018ed1f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장 전, 데이터가 잘 들어왔는지, 총 개수가 얼마나 되는지 확인함 (가독성 위해 코드 지움)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9abaf4-6d9d-40a4-bf88-7d0c073ee67f",
   "metadata": {},
   "source": [
    "## 편의점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27cf2ff5-fbaa-4701-ac5e-cd7ccaf99b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CU = make_brand(327)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f85aa28a-a148-4e2c-a097-e66f0c9bb34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GS = make_brand(145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f64f8e-2aaf-4fc0-977d-5f392489e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SV = make_brand(147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d554eff-5a16-4c1f-b277-988106504b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장\n",
    "\n",
    "df_CU.to_csv(\".\\\\Convenience_CU.csv\", header=True, sep=',')\n",
    "df_GS.to_csv(\".\\\\Convenience_GS.csv\", header=True, sep=',')\n",
    "df_SV.to_csv(\".\\\\Convenience_SV.csv\", header=True, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b8cac-9747-4bfa-bef3-86efe1a9583b",
   "metadata": {},
   "source": [
    "## 커피(고가형)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27967203-98f8-455f-bb6f-bce3f84330ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SB = make_brand(148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5ef65b0-9e83-4c6b-a06f-6adc28d067b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TS = make_brand(328)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5aee2d54-f375-4d15-a560-299eb451a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ED = make_brand(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7ea3f10-e589-4e8b-9a8d-5ff0c8463426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PC = make_brand(931)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0aa6c97c-b2b8-4233-ae77-93237deb76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장\n",
    "\n",
    "df_SB.to_csv(\".\\\\coffeeH_SB.csv\", header=True, sep=',')\n",
    "df_TS.to_csv(\".\\\\coffeeH_TS.csv\", header=True, sep=',')\n",
    "df_ED.to_csv(\".\\\\coffeeH_ED.csv\", header=True, sep=',')\n",
    "df_PC.to_csv(\".\\\\coffeeH_PC.csv\", header=True, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c71167b-a312-4461-8b76-362ff9ab888f",
   "metadata": {},
   "source": [
    "## 커피(저가형)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70ac484e-0206-4001-9ad5-4a6bf6122213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MG = make_brand(491)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93b80350-b289-4d95-9d1e-ead46252cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PK = make_brand(1276)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "abaa1390-2e0d-45c3-9ed2-78e2abfce9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CP = make_brand(14624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faec32b9-05c6-4bf0-8a27-be74ecdc9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TB = make_brand(944)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9766e30d-48c3-4e6e-839a-f3ecbdfd953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장\n",
    "\n",
    "df_MG.to_csv(\".\\\\coffeeL_MG.csv\", header=True, sep=',')\n",
    "df_PK.to_csv(\".\\\\coffeeL_PK.csv\", header=True, sep=',')\n",
    "df_CP.to_csv(\".\\\\coffeeL_CP.csv\", header=True, sep=',')\n",
    "df_TB.to_csv(\".\\\\coffeeL_TB.csv\", header=True, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c8c7d-5953-45e5-a76c-f3415fb96d55",
   "metadata": {},
   "source": [
    "## spa브랜드 옷가게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cfc6a28-160e-46b7-b163-e847f349b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UC = make_brand(576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50ccb122-db83-4a55-9377-84c2385152d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TT = make_brand(665) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f59214e0-14e9-4596-9dff-cb0c3df1c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8S = make_brand(551)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82a7f8a6-d35e-4590-b738-9f2cf148d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MS = make_brand(620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "897f767f-ec23-40fc-8263-5ac90f9855cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413\n"
     ]
    }
   ],
   "source": [
    "print(len(df_UC)+len(df_TT)+len(df_8S)+len(df_MS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "533b4cc8-e88d-4ef9-a776-1f4739890adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장\n",
    "\n",
    "df_UC.to_csv(\".\\\\clothes_UC.csv\", header=True, sep=',')\n",
    "df_TT.to_csv(\".\\\\clothes_TT.csv\", header=True, sep=',')\n",
    "df_8S.to_csv(\".\\\\clothes_8S.csv\", header=True, sep=',')\n",
    "df_MS.to_csv(\".\\\\clothes_MS.csv\", header=True, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdec7b2-2e9c-42a3-98ae-ab970598b663",
   "metadata": {},
   "source": [
    "## 영화관,놀이공원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be7ab1aa-e26e-42fb-90a3-d9f58f241d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CGV = make_brand(403)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32a615f8-7a9f-417b-9261-fd59482495d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MB = make_brand(927)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1498aba-a2da-40a9-a9a4-e77bbbcfdc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LC = make_brand(274)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "878d7f98-06a8-4f55-a2b5-ea0f25258051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906\n"
     ]
    }
   ],
   "source": [
    "print(len(df_CGV)+len(df_MB)+len(df_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff0b2cf3-9483-4c2f-b383-c29b108cea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장\n",
    "\n",
    "df_CGV.to_csv(\".\\\\theater_CGV.csv\", header=True, sep=',')\n",
    "df_MB.to_csv(\".\\\\theater_MB.csv\", header=True, sep=',')\n",
    "df_LC.to_csv(\".\\\\theater_LC.csv\", header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c4438-b461-4998-85d2-ab3deb4da060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a100b5-f3e3-45cf-9b8a-b6171e368dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b64e5d-31ed-4e46-9526-ce88b9777f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b709264-2767-44d7-834b-4f455ed40be7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 히든버튼(오류수정용 임시저장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "88988296-c61d-4b50-91b9-dbee19bd97f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Icon_icon__BlZpj icon-system_arrowUp\n",
      "열림\n",
      "할만해요2017-07-24 13:152016년 3월 ~\n",
      "            2017년 2월 근무좋았어요 8아쉬워요 0Q. 일하면서 좋았던 점/힘들었던 점을 알려주세요!근무환경 쾌적해요자유로운 분위기예요Q. 사장님은 어떤 분이셨나요?알바생을 존중해줘요시간,일정 고려해줘요Q. 동료들은 어땠나요?친절하고 잘챙겨줘요성실해요Q. 급여일 약속은 잘 지켜졌나요?제때 나와요Q. 급여는 만족하시나요?만족해요후기가 도움되었나요?도움돼요! 0\n",
      "Icon_icon__BlZpj icon-system_arrowUp\n",
      "열림\n",
      "할만해요2017-07-24 12:302016년 6월 ~\n",
      "            2016년 12월 근무좋았어요 5아쉬워요 1\n",
      "Icon_icon__BlZpj icon-system_arrowUp\n",
      "열림\n",
      "할만해요2017-07-24 12:142012년 7월 ~\n",
      "            2012년 8월 근무좋았어요 6아쉬워요 0\n"
     ]
    }
   ],
   "source": [
    "# 페이지별 첫번째 리뷰 크롤링 안되면 하려고 체크해둔 히든 버튼 (크롤링이 문제 없이 잘되서 안썼음)\n",
    "\n",
    "# 0번 클릭 에러 수정 중\n",
    "    # if str(temp[0].find(\"i\")).split('\"')[3] ==\"Icon_icon__BlZpj icon-system_arrowDown\":\n",
    "    #     print(\"닫힘\")\n",
    "        \n",
    "    #     apple_btn_path = f'//*[@id=\"item_{review_num}summary\"]/div/div/div[2]/div[2]/i'\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66c99e-3a94-49c2-9f62-8de39bb7263a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
